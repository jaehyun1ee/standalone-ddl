{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec07_EMNIST_Model_Testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenko99/Standalone_DDL/blob/master/Lec07/Lec07_EMNIST_Model_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giWIxZgiWs1-",
        "colab_type": "text"
      },
      "source": [
        "#Grading EMNIST Models\n",
        "\n",
        "<br/>\n",
        "\n",
        "Google Drive의 **EMNIST** 폴더 안에 **emnist-models**라는 폴더를 새로 만드시고,\n",
        "\n",
        "그 안에 Model의 정보가 담긴 **.h5, .json** 파일들을 업로드해주세요.\n",
        "\n",
        "또, Github Repo의 Lec07 폴더에 업로드된 **emnist-custom.zip**을 받아서 압축을 푸시고, 나오는 **emnist-custom** 폴더를 폴더 그대로 **EMNIST** 안에 업로드해주세요.\n",
        "\n",
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO174u7qyYe-",
        "colab_type": "text"
      },
      "source": [
        "## Download and Preprocess Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSYfiEavlGLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGa7wMpdXqpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My Drive//EMNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Baco99qBXrUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYMozN2lH_5j",
        "colab_type": "text"
      },
      "source": [
        "### Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1YTTixs1S5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage as im\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hk6GT-H2Fv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some constants\n",
        "ascii_idx = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 100, 101, 102, 103, 104, 110, 113, 114, 116]\n",
        "img_path_prefix = ['emnist-custom/emnist-custom-digit/', 'emnist-custom/emnist-custom-large/', 'emnist-custom/emnist-custom-small/']\n",
        "img_path_postfix = ['.jpg', '_placeholder.jpg']\n",
        "\n",
        "test_data_custom = []\n",
        "test_labels_custom = []\n",
        "\n",
        "for i in range(len(ascii_idx)):\n",
        "    # Set image path\n",
        "    if(ascii_idx[i] >= 48 and ascii_idx[i] <= 57):\n",
        "        img_path = img_path_prefix[0]\n",
        "    elif(ascii_idx[i] >= 65 and ascii_idx[i] <= 90):\n",
        "        img_path = img_path_prefix[1]\n",
        "    else:\n",
        "        img_path = img_path_prefix[2]\n",
        "    img_path = img_path + chr(ascii_idx[i]) + img_path_postfix[0]\n",
        "    \n",
        "    # Read image and append to test data / labels (actual handwriting. already made)\n",
        "    test_data_custom.append(im.util.invert(im.color.rgb2gray(im.io.imread(img_path))))\n",
        "    test_labels_custom.append(i)\n",
        "    \n",
        "test_data_custom = np.array(test_data_custom)\n",
        "test_labels_custom = np.array(test_labels_custom)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib8Jn5mWIEAm",
        "colab_type": "text"
      },
      "source": [
        "###Predefined Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ki9g1ZBOu4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcgRpDpUIClb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read csv file\n",
        "df = pd.read_csv('emnist-balanced-test.csv', header=None)\n",
        "\n",
        "# Shuffle Dataset\n",
        "np.random.seed(10)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "\n",
        "# Separate into Data / Label\n",
        "test_data = df.iloc[:, 1:].values / 255\n",
        "test_labels = df.iloc[:, 0].values\n",
        "\n",
        "# Reshape Data\n",
        "test_data = test_data.reshape((test_data.shape[0], 28, -1))\n",
        "test_data = np.transpose(test_data, (0, 2, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghzdd4q12I0z",
        "colab_type": "text"
      },
      "source": [
        "##Visualize Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwuJwR8BzMms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRaKPrCz1o86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(data, labels, idx=0):\n",
        "    fig = plt.figure()\n",
        "    for i in range(10):\n",
        "        ax = fig.add_subplot(2, 5, i + 1)\n",
        "        image = data[idx]\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(\"label = {}\".format(chr(ascii_idx[labels[idx]])))\n",
        "        idx += 1\n",
        "    plt.subplots_adjust(hspace = 0.5, wspace = 0.3)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"The shape of the image is {}\".format(image.shape))\n",
        "\n",
        "print(\"CUSTOM DATASET\")\n",
        "visualize(test_data_custom, test_labels_custom)\n",
        "print(\"PREDEFINED DATASET\")\n",
        "visualize(test_data, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxRo6q6W8RRM",
        "colab_type": "text"
      },
      "source": [
        "## Download Model Architecture / Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWOIUWry9LeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdcBjUnBOaqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "model_names = []\n",
        "\n",
        "for filename in os.listdir('./emnist-models'):\n",
        "    if filename.endswith('.json'):\n",
        "        path = os.path.join('./emnist-models', filename)\n",
        "        with open(path, 'r') as f:\n",
        "            model_tmp = tf.keras.models.model_from_json(f.read())\n",
        "        path = path[:-17]\n",
        "        path = path + 'weights.h5'\n",
        "        model_tmp.load_weights(path)\n",
        "        models.append(model_tmp)\n",
        "        model_names.append(path[16:-11])\n",
        "        continue\n",
        "    else:\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPx5jNRDzuR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqUrtlo98rv3",
        "colab_type": "text"
      },
      "source": [
        "##Test Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Yk-54vIZmx",
        "colab_type": "text"
      },
      "source": [
        "###Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_2pQDFk9X1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape Data so that Conv2D is applicable\n",
        "test_data_custom = test_data_custom.reshape((test_data_custom.shape[0], test_data_custom.shape[1], test_data_custom.shape[2], -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "244_nrEp8ncj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_custom(model):\n",
        "    prediction_custom = np.argmax(model.predict(test_data_custom), 1)\n",
        "\n",
        "    acc_custom = 0\n",
        "    for i in range(len(test_data_custom)):\n",
        "        if prediction_custom[i] == test_labels_custom[i]:\n",
        "            acc_custom += 1\n",
        "    acc_custom /= len(test_data_custom)\n",
        "\n",
        "    print('Accuracy over Custom Test Set is {}%'.format(round(acc_custom, 5) * 100))\n",
        "    \n",
        "    return round(acc_custom, 5) * 100\n",
        "\n",
        "    #test_data_custom = test_data_custom.reshape((test_data_custom.shape[0], test_data_custom.shape[1], -1))\n",
        "\n",
        "    #visualize(test_data_custom, prediction_custom)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7pSw2o7IpMH",
        "colab_type": "text"
      },
      "source": [
        "###Predefined Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uMq86VVIrOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape Data so that Conv2D is applicable\n",
        "test_data = test_data.reshape((test_data.shape[0], test_data.shape[1], test_data.shape[2], -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "togxDKzJI0FC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_predefined(model):\n",
        "    prediction = np.argmax(model.predict(test_data), 1)\n",
        "\n",
        "    acc = 0\n",
        "    for i in range(len(test_data)):\n",
        "        if prediction[i] == test_labels[i]:\n",
        "            acc += 1\n",
        "    acc /= len(test_data)\n",
        "\n",
        "    print('Accuracy over Predefined Test Set is {}%'.format(round(acc, 5) * 100))\n",
        "    \n",
        "    return round(acc, 5) * 100\n",
        "\n",
        "    #test_data = test_data.reshape((test_data.shape[0], test_data.shape[1], -1))\n",
        "\n",
        "    #visualize(test_data, prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o65EkyrMRtim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_custom = {}\n",
        "res_predefined = {}\n",
        "\n",
        "for i in range(len(models)):\n",
        "    print('\\nModel : {}\\n'.format(model_names[i]))\n",
        "    res_custom.update({model_names[i] : test_custom(models[i])})\n",
        "    res_predefined.update({model_names[i] : test_predefined(models[i])})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unMi4CpOe3nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "\n",
        "res_custom = sorted(res_custom.items(), key=operator.itemgetter(1),reverse=True)\n",
        "res_predefined = sorted(res_predefined.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "print(\"LEADERBOARD : CUSTOM DATASET\\n\")\n",
        "for i in range(len(res_custom)):\n",
        "    print(res_custom[i])\n",
        "print(\"\\nLEADERBOARD : PREDEFINED DATASET\\n\")\n",
        "for i in range(len(res_predefined)):\n",
        "    print(res_predefined[i])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}