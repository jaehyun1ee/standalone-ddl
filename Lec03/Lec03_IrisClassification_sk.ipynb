{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec03_IrisClassification_sk.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenko99/Standalone_DDL/blob/master/Lec03/Lec03_IrisClassification_sk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a7isqC46O03",
        "colab_type": "text"
      },
      "source": [
        "Open in Colab이 열리지 않으면 [여기](https://drive.google.com/open?id=10g-5Ltp42V1UbEsPrFT0WI3EfYpaFZJe)를 클릭하세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaQCcEoQ5U4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "iris_data = iris.data\n",
        "iris_labels = iris.target\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(iris_data)\n",
        "df2 = pd.DataFrame(iris_labels)\n",
        "df = pd.concat([df, df2], axis=1, sort=False)\n",
        "df.columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Classes']\n",
        "\n",
        "np.random.seed(7)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "\n",
        "iris_data = df.iloc[:, :4].values\n",
        "iris_labels = df.iloc[:, 4].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHPT_aReAKLs",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Set train_x and train_y for training data\n",
        "\n",
        "Set test_x and test_y for testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFY2GS8Ot2k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train_data = 135\n",
        "\n",
        "train_x = iris_data[ : n_train_data]\n",
        "train_y = iris_labels[ : n_train_data]\n",
        "test_x = iris_data[n_train_data : ]\n",
        "test_y = iris_labels[n_train_data : ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udSBKbq95J7-",
        "colab_type": "text"
      },
      "source": [
        "# Score Function\n",
        "\n",
        "\n",
        "$ f(X) = WX + B$\n",
        "\n",
        "$W.shape = (3,4)$\n",
        "\n",
        "$X.shape = (4, )$\n",
        "\n",
        "$B.shape = (3, )$\n",
        "\n",
        "$f(X).shape = (3, )$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYhfGsFw26Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_function(X, weight, bias):\n",
        "    return weight.dot(X) + bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JKrUpOhn92t",
        "colab_type": "text"
      },
      "source": [
        "#SVM Loss\n",
        "\n",
        "##$L_{i} = \\underset{j\\neq y_i}\\sum max(0 \\ ,\\ s_j - s_{y_i} + \\triangle )$\n",
        "\n",
        "##$L = {1\\over N}\\underset{i=1}{\\overset{N}\\sum} L_{i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS_yshtsn9Ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm_loss(scores, y_i):\n",
        "    loss = np.maximum(0 , scores - scores[y_i] + 1)\n",
        "    loss[y_i] = 0\n",
        "    return np.sum(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4J4Mk9veS9g",
        "colab_type": "text"
      },
      "source": [
        "#Softmax Function and Cross-entropy Loss\n",
        "\n",
        "##$p_{i} = { e^{s_{y_i} - max(s) }\\over\\underset{j}\\sum{ e^ {s_{j} - max(s)}  } }$\n",
        "\n",
        "##$L_{i} = -\\ log( p_{i}) $\n",
        "\n",
        "##$L = {1\\over N}\\underset{i=1}{\\overset{N}\\sum} L_{i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnvsLzguwiDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(scores):\n",
        "    exps = np.exp(scores - np.max(scores))\n",
        "    return exps / np.sum(exps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8g0f_QvoNY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy_loss(scores, y_i):\n",
        "    return - np.log(softmax(scores)[y_i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd3xKoggQ-cl",
        "colab_type": "text"
      },
      "source": [
        "#L2 Regularization\n",
        "\n",
        "###$R(W) = \\underset{k}\\sum\\underset{l}\\sum {W_{kl}}^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVc3sh86Q-8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def l2_reg(W):\n",
        "    return np.sum(np.square(W))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsrQGbB2_jN1",
        "colab_type": "text"
      },
      "source": [
        "#Numeric Gradient Check\n",
        "\n",
        "##$f'(W) = {f(W + h) - f(W - h) \\over 2h}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWaGFO6RAGJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numeric_grad_check(W, B, loss_fun, h, lmb):\n",
        "    grad_w = np.zeros(W.shape)\n",
        "    grad_b = np.zeros(B.shape)\n",
        "    \n",
        "    for i in range(W.shape[0]):\n",
        "        for j in range(W.shape[1]):\n",
        "            w1 = W.copy()\n",
        "            w2 = W.copy()\n",
        "            w1[i][j] += h\n",
        "            w2[i][j] -= h\n",
        "            for k in range(len(train_x)):\n",
        "                grad_w[i][j] += ( loss_fun(score_function(train_x[k], w1, B), train_y[k]) - loss_fun(score_function(train_x[k], w2, B), train_y[k]) ) /  (2*h)\n",
        "    grad_w /= len(train_x)\n",
        "    grad_w += lmb * 2 * W\n",
        "    \n",
        "    for i in range(B.shape[0]):\n",
        "        b1 = B.copy()\n",
        "        b2 = B.copy()\n",
        "        b1[i] += h\n",
        "        b2[i] -= h\n",
        "        for j in range(len(train_x)):\n",
        "            grad_b[i] += ( loss_fun(score_function(train_x[j], W, b1), train_y[j]) - loss_fun(score_function(train_x[j], W, b2), train_y[j]) ) /  (2*h)\n",
        "    grad_b /= n_train_data\n",
        "    \n",
        "    return grad_w, grad_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcJl9C_Jeakc",
        "colab_type": "text"
      },
      "source": [
        "# Train\n",
        "\n",
        "\n",
        "###$Gradient \\ Update\\ (SVM)$\n",
        "##$\\begin{cases}\n",
        "{\\partial L_{i} \\over \\partial w_{y_i} } = 1(s_j - s_{y_i} + 1 > 0) \\cdot x_{i}^{T} \\\\\n",
        "{\\partial L_{i} \\over \\partial w_{j} } = \\underset{j \\ne y_i}\\sum 1(s_j - s_{y_i} + 1 > 0) \\cdot x_{i}^{T}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "##$\\begin{cases}\n",
        "{\\partial L_{i} \\over \\partial b_{y_i} } = 1(s_j - s_{y_i} + 1 > 0) \\\\\n",
        "{\\partial L_{i} \\over \\partial b_{j} } = \\underset{j \\ne y_i}\\sum 1(s_j - s_{y_i} + 1 > 0)\n",
        "\\end{cases}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TrGswpc128r",
        "colab_type": "text"
      },
      "source": [
        "###$Gradient \\ Update\\ (Cross-Entropy)$\n",
        "##$\\begin{cases}\n",
        "{\\partial L_{i} \\over \\partial w_{y_i} } = - x_i + p_i \\cdot x_{i}^{T} \\\\\n",
        "{\\partial L_{i} \\over \\partial w_{j} } = p_i \\cdot x_{i}^{T}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "##$\\begin{cases}\n",
        "{\\partial L_{i} \\over \\partial b_{y_i} } = - 1+ p_i  \\\\\n",
        "{\\partial L_{i} \\over \\partial b_{j} } = p_i\n",
        "\\end{cases}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afNwYS6U8dc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_update(weight, bias, loss_fun, i):\n",
        "\n",
        "    \"\"\"\n",
        "    L_i에 대해 grad_w와 grad_b를 구해준 뒤 리턴해준다.\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.zeros(weight.shape), np.zeros(bias.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRU2GNOD6OjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(weight, bias, lr, lmb, loss_fun):\n",
        "    \n",
        "    train_loss = 0\n",
        "    grad_w = np.zeros(weight.shape)\n",
        "    grad_b = np.zeros(bias.shape)\n",
        "    acc = 0\n",
        "    \n",
        "    for i in range(135):\n",
        "        scores = score_function(train_x[i], weight, bias)\n",
        "        loss = loss_fun(scores, train_y[i])\n",
        "        train_loss += loss\n",
        "        \n",
        "        update_w, update_b = gradient_update(weight, bias, loss_fun, i)\n",
        "        grad_w += update_w\n",
        "        grad_b += update_b\n",
        "        \n",
        "        if train_y[i] == scores.argmax():\n",
        "            acc += 1\n",
        "    \n",
        "    train_loss /= n_train_data\n",
        "    train_loss += lmb * l2_reg(weight)\n",
        "    \n",
        "    \"\"\"\n",
        "    L_i에 대한 grad_w, grad_b를 더했으니 전체 N(n_train_data)로 나눠주고, 정규화 항을 더해준다.\n",
        "    \"\"\"\n",
        "    \n",
        "    grad_w, grad_b = numeric_grad_check(weight, bias, loss_fun, h=0.00001, lmb=lmb)\n",
        "    \n",
        "    weight -= lr * grad_w\n",
        "    bias -= lr * grad_b\n",
        "    \n",
        "    result = {}\n",
        "    result['weight'] = weight\n",
        "    result['accuracy'] = acc / n_train_data\n",
        "    result['train_loss'] = train_loss\n",
        "    result['gradient_w'] = grad_w\n",
        "    result['bias'] = bias\n",
        "    result['gradient_b'] = grad_b\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyf-vZ7OtBo-",
        "colab_type": "text"
      },
      "source": [
        "# Test\n",
        "\n",
        "- calculate accuracy for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpuHtaHc1l5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(weight, bias, loss_fun):\n",
        "    \n",
        "    test_loss = 0\n",
        "    acc = 0\n",
        "    \n",
        "    for i in range(15):\n",
        "        scores = score_function(test_x[i], weight, bias)\n",
        "        \n",
        "        test_loss += loss_fun(scores, test_y[i])\n",
        "        \n",
        "        if test_y[i] == scores.argmax():\n",
        "            acc += 1\n",
        "                \n",
        "    test_loss /= len(test_x)\n",
        "    \n",
        "    result = {}\n",
        "    result['test_loss'] = test_loss\n",
        "    result['accuracy'] = acc / len(test_x)\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsrgYJGJlzhF",
        "colab_type": "text"
      },
      "source": [
        "# Experience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEbcMuiIK_QC",
        "colab_type": "code",
        "outputId": "3ebfb644-f8e8-4e13-9c00-5db11775bc42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "np.random.seed(123)\n",
        "Weight = np.random.uniform(-2, 2, (3,4))\n",
        "Bias = np.random.uniform(-5, 5, (3,))\n",
        "\n",
        "grad_wn, grad_bn = numeric_grad_check(Weight, Bias, cross_entropy_loss, 0.00001, lmb=0.01)\n",
        "result = train(Weight, Bias, lr=0.05, lmb=0.01, loss_fun=cross_entropy_loss)\n",
        "grad_wa = result['gradient_w']\n",
        "grad_ba = result['gradient_b']\n",
        "\n",
        "\n",
        "print(grad_wa[0][0])\n",
        "print(grad_wn[0][0])\n",
        "print(grad_ba[0])\n",
        "print(grad_bn[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.607641566378958\n",
            "-1.607641566378958\n",
            "-0.3232562561881207\n",
            "-0.3232562561881207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMFiUcnuGH4",
        "colab_type": "code",
        "outputId": "6bef1468-bf96-40a3-9d45-164f06688b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "np.random.seed(123)\n",
        "weight = np.random.uniform(-2, 2, (3,4))\n",
        "bias = np.random.uniform(-5, 5, (3,))\n",
        "lr = 0.005\n",
        "lmb = 0.001\n",
        "epoch = 100\n",
        "loss_fun = cross_entropy_loss\n",
        "\n",
        "hyperp = {}\n",
        "hyperp['lr'] = lr\n",
        "hyperp['epoch'] = epoch\n",
        "hyperp['lambda'] = lmb\n",
        "hyperp['loss_fun'] = loss_fun\n",
        "\n",
        "result = {}\n",
        "result['train_loss'] = []\n",
        "result['epoch'] = []\n",
        "result['gradient'] = []\n",
        "result['accuracy'] = []\n",
        "result['val_loss'] = []\n",
        "result['val_epoch'] = []\n",
        "\n",
        "for i in range(epoch):\n",
        "    traind = train(weight, bias, lr, lmb, loss_fun)\n",
        "    result['train_loss'].append(traind['train_loss'])\n",
        "    result['epoch'].append(i)\n",
        "    result['gradient'].append(traind['gradient_w'])\n",
        "    result['accuracy'].append(traind['accuracy'])\n",
        "    weight, bias = traind['weight'], traind['bias']\n",
        "    \n",
        "    if i%10 == 0:\n",
        "        val = validation(weight, bias, loss_fun)\n",
        "        result['val_loss'].append(val['test_loss'])\n",
        "        result['val_epoch'].append(i)\n",
        "\n",
        "print(\"Accuaracy for train set is {0:2.2%}\".format(traind['accuracy']))\n",
        "\n",
        "print(\"Accuaracy for validation set is {0:2.2%}\".format(val['accuracy']))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuaracy for train set is 41.48%\n",
            "Accuaracy for validation set is 46.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3deMC8N7uSVk",
        "colab_type": "text"
      },
      "source": [
        "# Plot Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8kXV2aJuU26",
        "colab_type": "code",
        "outputId": "cc6222eb-4c2a-4c84-fa4e-2871e66b6a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.title('Train loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('train_loss')\n",
        "plt.plot(result['epoch'], result['train_loss'])\n",
        "plt.plot(result['val_epoch'], result['val_loss'], color = 'orange')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.title('Gradient')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('gradient')\n",
        "plt.plot(result['epoch'], [result['gradient'][i][0][0] for i in range(epoch)], color = 'red')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"learning rate is {0} and epoch is {1}\".format(hyperp['lr'], hyperp['epoch']))\n",
        "print(\"regularization rate is {0} and loss function is {1}\".format(hyperp['lambda'], hyperp['loss_fun']))\n",
        "print(\"Accuracy For Train Set is {0:2.2%}\".format(result['accuracy'][-1]))\n",
        "print(\"Accuracy For Test Set is {0:2.2%}\".format(val['accuracy']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "learning rate is 0.005 and epoch is 100\n",
            "regularization rate is 0.001 and loss function is <function cross_entropy_loss at 0x7f15def78b70>\n",
            "Accuracy For Train Set is 41.48%\n",
            "Accuracy For Test Set is 46.67%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}